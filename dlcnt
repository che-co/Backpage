#!/bin/bash 
#  This script is used to download and extract page content
#+ scraped using scraper.sh
#  Usage: dlcnt ["NS" "S"] geography category URLfileaname

E_WRONG_ARGS=85
E_EMPTY_PATH=84
E_EMPTY_CONTENT=44

if [ "$1" != "NS" -a "$1" != "S" ]; then
  echo "`basename "$0"`: content type incorrectly specified" >&2
  echo Usage: "$0" ["NS" "S"] geography category URLfilename >&2
  exit "$E_WRONG_ARGS"
fi
if [ -z "$2" ]; then
  echo "`basename "$0"`: geography not specified" >&2
  echo Usage: "$0" ["NS" "S"] geography category URLfilename >&2
  exit "$E_WRONG_ARGS"
fi
if [ -z "$3" ]; then
  echo "`basename "$0"`: category not specified" >&2
  echo Usage: "$0" ["NS" "S"] geography category URLfilename >&2
  exit "$E_WRONG_ARGS"
fi
if [ -z "$4" ]; then
  echo "`basename "$0"`: URLfilename not specified" >&2
  echo Usage: "$0" ["NS" "S"] geography category URLfilename >&2
  exit "$E_WRONG_ARGS"
fi
CPATH=""$1"CPATH"
UPATH=""$1"UPATH"
GEOG="$2"
if [ -z "${!CPATH}" ]; then
  echo "`basename "$0"`": content path not set >&2
  exit $E_EMPTY_PATH
fi

if [ -z "${!UPATH}" ]; then
  echo "`basename "$0"`: URL path not set" >&2
  exit $E_EMPTY_PATH
fi
if [ ! -s "${!UPATH}"/"$4"_"$1".txt ]; then
  echo "${!UPATH}"/"$4"_"$1".txt is empty\; no new content exists to download
  exit 0
fi

if [ "$1" == "S" ]; then
  CTYPE=1
else
  CTYPE=0
fi

while read URL; do
  curl -s "http://"$GEOG".backpage.com"$URL"" > "${!CPATH}"/.ad.txt
  WRITEBODY=0
	
  #  Extract posting's body content
  while read LINE; do
    grep -q "</div>" <(echo "$LINE")
    if [ $? -eq 0 -a "$WRITEBODY" -eq 1 ]; then
      break
    fi
    if [ "$WRITEBODY" -eq 1 ]; then
      BODY="${BODY}""${LINE}"$'\n'
    fi
    grep -q "<div class=\"postingBody\">" <(echo "$LINE")
    if [ $? -eq 0 ]; then
      WRITEBODY=1
    fi
  done < "${!CPATH}"/.ad.txt
  BODY=`./clnvar "${BODY//<br>/ }"`
  
  #  Extract date and time of posting
  DATETIME=`grep -o "[[:upper:]][[:lower:]]\+, [[:upper:]][[:lower:]]\+ [0-9]\+, [0-9]\{4\} [0-9]\+:[0-9]\{2\} [APM]*" "${!CPATH}"/.ad.txt`
  #  Extract "poster's" age
  AGE=`grep -oP "(?<=Poster's age: )[0-9]*" "${!CPATH}"/.ad.txt`

  #  Extract location information
  LOCATION=`pcregrep -oM "(?<=Location:)\W*?.*\W*?(?=</div)" "${!CPATH}"/.ad.txt`
  LOCATION=`./clnvar "$LOCATION"`

  #  Extract Post ID to other postings
  ID=`grep -oP '(?<=Post ID: )[0-9]*' "${!CPATH}"/.ad.txt`
		
  if [ -z "$BODY" -o -z "$DATETIME" -o -z "$AGE" -o -z "$ID" ]; then
    echo "`basename "$0"`: some or all of the minumum expected content was not found for \"http://"$GEOG".backpage.com"$URL"\"" >&2
    exit $E_EMPTY_CONTENT
  fi
 #  Extract "Other Ads by this user"
  OTHERADS=`grep -v "http://"$GEOG".backpage.com/"$URL"" <(grep -o "http://[a-z]\+\./backpage\.com/"$3"/[a-z\-]\+/[0-9]\+" "${!CPATH}"/.ad.txt)`

  #  Write content to file and download images
  if [ ! -d "${!CPATH}"/"$ID" ]; then
    mkdir -p "${!CPATH}"/"$ID"/imgs
    CCPATH="${!CPATH}"/"$ID"
  else
    CCPATH="${!CPATH}"/"$ID"\(`ls "${!CPATH}" | grep -c "$ID"`\)
    mkdir -p "${!CPATH}"/"$ID"\(`ls "${!CPATH}" | grep -c "$ID"`\)/imgs
    echo "$3" ID: "$ID" already exists and may be duplcated
  fi

  IPATH="$CCPATH"/imgs

  echo "$DATETIME" > "$CCPATH"/datetime.txt
  echo "$BODY"	 > "$CCPATH"/body.txt
  echo "$AGE"	 > "$CCPATH"/age.txt
  echo "$LOCATION" > "$CCPATH"/location.txt
  echo http://"$GEOG".backpage.com"$URL" > "$CCPATH"/url.txt
  if [ ! -z "$OTHERADS" ]; then
    echo "$OTHERADS" > "$CCPATH"/otheradurls.txt
  fi

  IMGURL=`paste -sd, <(grep -Po '(?<=(img src="))[^ ]*(?=")' "${!CPATH}"/.ad.txt)`
  if [ ! -z "$IMGURL" ]; then
    cd "$IPATH"
    echo writing pictures for "$ID" to "$IPATH"
    curl -Os "{"$IMGURL"}"
    cd - > /dev/null
  fi
  
  echo writing contents for "$ID" to "$CCPATH"
  echo "\""$DATETIME"\",\""$BODY"\","$AGE",\""$LOCATION"\","$ID","$CTYPE",http://"$GEOG".backpage.com"$URL"" >> ./content/"$GEOG"/"$3"/posting_content_raw.csv

  BODY=;DATETIME=;AGE=;LOCATION=;ID=;OTHERADS=;IMGURL=
done < "${!UPATH}"/"$4"_"$1".txt
sleep 10
exit $?
