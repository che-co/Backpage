#!/bin/bash
#  This script is used to download and extract page content
#+ scraped using scraper.sh
#  Usage: dlcnt ["NS" "S"] geography category URLfileaname

E_WRONG_ARGS=85

if [ "$1" != "NS" -a "$1" != "S" ]; then
  echo "$0": content type incorrectly specified
  echo Usage: "$0" ["NS" "S"] geography category URLfilename
  exit "$E_WRONG_ARGS"
fi
if [ -z "$2" ]; then
  echo "$0": geography not specified
  echo Usage: "$0" ["NS" "S"] geography category URLfilename
  exit "$E_WRONG_ARGS"
fi
if [ -z "$3" ]; then
  echo "$0": category not specified
  echo Usage: "$0" ["NS" "S"] geography category URLfilename
  exit "$E_WRONG_ARGS"
fi
if [ -z "$4" ]; then
  echo "$0": URLfilename not specified
  echo Usage: "$0" ["NS" "S"] geography category URLfilename
  exit "$E_WRONG_ARGS"
fi

CPATH=""$1"CPATH"
UPATH=""$1"UPATH"
GEOG="$2"
if [ -z "${!CPATH}" ]; then
  echo "$0": content path not set
  exit 1
fi

if [ -z "${!UPATH}" ]; then
  echo "$0": URL path not set
  exit 1
fi
if [ "$1" == "S" ]; then
  CTYPE=1
else
  CTYPE=0
fi

while read URL; do
  curl -s "http://"$GEOG".backpage.com/"$URL"" > "${!CPATH}"/.ad.txt
  WRITEBODY=0
	
  #  Extract posting's body content
  while read LINE; do
    grep -q "</div>" <(echo "$LINE")
    if [ $? -eq 0 -a "$WRITEBODY" -eq 1 ]; then
      break
    fi
    if [ "$WRITEBODY" -eq 1 ]; then
      BODY="${BODY}""${LINE}"$'\n'
    fi
    grep -q "<div class=\"postingBody\">" <(echo "$LINE")
    if [ $? -eq 0 ]; then
      WRITEBODY=1
    fi
  done < "${!CPATH}"/.ad.txt
  BODY=`./clnvar "${BODY//<br>/ }"`

  #  Extract date and time of posting
  DATETIME=`grep -o "[[:upper:]][[:lower:]]\+, [[:upper:]][[:lower:]]\+ [0-9]\+, [0-9]\{4\} [0-9]\+:[0-9]\{2\} [APM]*" "${!CPATH}"/.ad.txt`
  #  Extract "poster's" age
  AGE=`grep -oP "(?<=Poster's age: )[0-9]*" "${!CPATH}"/.ad.txt`

  #  Extract location information
  LOCATION=`pcregrep -oM "(?<=Location:)\W*?.*\W*?(?=</div)" "${!CPATH}"/.ad.txt`
  LOCATION=`./clnvar "$LOCATION"`

  #  Extract Post ID to other postings
  ID=`grep -oP '(?<=Post ID: )[0-9]*' "${!CPATH}"/.ad.txt`
		
  #  Extract "Other Ads by this user"
  OTHERADS=`grep -v "http://"$GEOG".backpage.com/"$URL"" <(grep -o "http://[a-z]\+\./backpage\.com/"$3"/[a-z\-]\+/[0-9]\+" "${!CPATH}"/.ad.txt)`

  #  Write content to file and download images
  if [ ! -d "${!CPATH}"/"$ID" ]; then
    mkdir -p "${!CPATH}"/"$ID"/imgs
    CCPATH="${!CPATH}"/"$ID"
  else
    CCPATH="${!CPATH}"/"$ID"\(`ls "${!CPATH}" | grep -c "$ID"`\)
    mkdir -p "${!CPATH}"/"$ID"\(`ls "${!CPATH}" | grep -c "$ID"`\)
    echo ID: "$ID" already exists and may be duplcated
  fi

  IPATH="$CCPATH"/imgs

  echo "$DATETIME" > "$CCPATH"/datetime.txt
  echo "$BODY"	 > "$CCPATH"/body.txt
  echo "$AGE"	 > "$CCPATH"/age.txt
  echo "$LOCATION" > "$CCPATH"/location.txt
  if [ ! -z "$OTHERADS" ]; then
    echo "$OTHERADS" > "$CCPATH"/otheradurls.txt
  fi

  IMGURL=`paste -sd, <(grep -Po '(?<=(img src="))[^ ]*(?=")' "${!CPATH}"/.ad.txt)`
  if [ ! -z "$IMGURL" ]; then
    cd "$IPATH"
    echo writing pictures for "$ID" to "$IPATH"
    curl -Os "{"$IMGURL"}"
    cd - > /dev/null
  fi
  
  echo writing contents for "$ID" to "$CCPATH"
  echo "\""$DATETIME"\",\""$BODY"\","$AGE",\""$LOCATION"\","$ID","$CTYPE"" >> ./content/"$GEOG"/"$3"/posting_content_raw.csv
 
  BODY=;DATETIME=;AGE=;LOCATION=;ID=;OTHERADS=;IMGURL=;
done < "${!UPATH}"/"$4"_"$1".txt

exit $?
