#!/bin/bash  

#  To-do: 
#  (1) Check to see if other scraper is running and pages
#+    -have downloaded

#  Author: Sergio "Checo" Gonzales
#  Date: 07-31-2016
#  This was designed to scrape the escort ads of backpage.com

#  Error Codes
E_WRONG_ARG=85
E_BAD_REQUEST=500

usage () {
  echo "`basename "$0"`: usage: --duplicate --no-tor --type=[non/sponsored] category,category,... geography geography ..."
  exit $E_WRONG_ARG
}

#  Source configuration file
source ./.scraper.conf

#  Create signaling file to inform dlcnt.sh that URLs are currently
#+ being copyied to file to prevent early termination
touch ./.dontstop

#  Set option variables
TOR=true
C_OPT=false

while :; do
  case $1 in 
    -d | --duplicate )
      C_OPT=true ;;
    -n | --no-tor ) 
      TOR=false ;;
    -t | --type )
      if [ ! -z "$2" ]; then
        TYPE="$2"
        shift
      else
        echo "`basename "$0"`: \"--type\" requires an argument and has no default." >&2
        exit $E_WRONG_ARGS
      fi ;;
    --type=?*)
      TYPE=${1#*=} ;;
    --)     
      shift; break ;;
    *) break ;;
  esac
  shift
done

if [ -z "$TYPE" ]; then
  usage
fi

if [ "$TYPE" = "non-sponsored" ]; then
  GREP_OPT="-v"
fi

if [ $TOR = true ]; then
  TOR_OPT=torify
else
  TOR_OPT=
fi

#  Set some more variables
CATEGORY="$1,"
DATE=`date +%d%m%Y_%H%M%S`

#  Scrape topics
until [ -z "$2" ]; do
  GEOG="$2"
  for X in `eval echo {$CATEGORY}`; do
    CAT="$X"
    UPATH=./URLs/"$GEOG"/"$CAT"/"$TYPE"
    PPATH=./.pages/"$GEOG"/"$CAT"
    PAGE=1
    FNAME="$DATE"

    if [ ! -d "$UPATH" ]; then
      mkdir -p "$UPATH"
    fi   
    if [ ! -d "$PPATH" ]; then
      mkdir -p "$PPATH"
    fi
    
    until [ "$PAGE" -gt 444 ]; do
      echo copying "$TYPE" URLs from: ""$GEOG".backpage.com/"$CAT"/"$PQUERY""$PAGE""
      $TOR_OPT curl -s -o "$PPATH"/"$FNAME"_pg"$PAGE" ""$GEOG".backpage.com/"$CAT"/"$PQUERY""$PAGE"" 

      ERR=`grep -o "Error [0-9]*" "$PPATH"/"$FNAME"_pg"$PAGE"`
      if [ ! -z "$ERR" ]; then
        echo "`basename "$0"`: HTTP $ERR" >&2
        if [ $TOR = false ]; then
          echo "--retrying with masked IP" >&2
          torify curl -s -o "$PPATH"/"$FNAME"_pg"$PAGE" ""$GEOG".backpage.com/"$CAT"/"$PQUERY""$PAGE"" 
          ERR2=`grep -o "Error [0-9]*" "$PPATH"/"$FNAME"_pg"$PAGE"`
          if [ ! -z "$ERR2" ]; then
            echo "--failed: HTTP $ERR2" >&2
            echo "$GEOG".backpage.com/"$CAT"/"$PQUERY""$PAGE" >> ./unsucccessful_urls
            break
          fi
        else
          echo "$GEOG".backpage.com/"$CAT"/"$PQUERY""$PAGE" >> ./unsuccessful_urls
          break
        fi
      fi

      grep -q  "<div><b>No matches found.</b><br><br></div>" "$PPATH"/"$FNAME"_pg"$PAGE"
      if [ $? -eq 0 ]; then
        break 
      fi
      grep $GREP_OPT "$GREP_QUERY" "$PPATH"/"$FNAME"_pg"$PAGE" | grep -o /"$CAT"/[a-z\-]*/[0-9]* | sort | uniq > "$UPATH"/.urls_"$DATE"
      if [ ! -s "$UPATH"/.urls_"$DATE" ]; then
        echo "`basename "$0"`: warning: no relevant $TYPE content found on "$GEOG".backpage.com/"$CAT"/"$PQUERY""$PAGE"" >&2
        break
      fi

      if [ `ls -A -1 "$UPATH"/ | wc -l` -le 1 ]; then 
        mv "$UPATH"/.urls_"$DATE" "$UPATH"/"$FNAME"
      else
        sort -u "$UPATH"/.urls_"$DATE" `ls -A -d  "$UPATH"/*` > "$UPATH"/._urls_"$DATE"
        if [ ! -s "$UPATH"/._urls_"$DATE" ]; then
          echo "no new unique urls found on page: "$GEOG".backpage.com/"$CAT"/"$PQUERY""$PAGE""
          if [ $C_OPT = true ]; then
            break
          fi
        fi 
        comm -23 "$UPATH"/._urls_"$DATE" "$UPATH"/.urls_"$DATE" > "$UPATH"/"$FNAME" 
        rm "$UPATH"/.urls_"$DATE" "$UPATH"/._urls_"$DATE" 
      fi
			
      ((PAGE+=1))
    done 
  done
  shift
done

rm .dontstop
exit $?
